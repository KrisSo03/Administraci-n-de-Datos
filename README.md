# ğŸ—“ PredicciÃ³n de Ausencias con Redes Neuronales

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.9%2B-orange)](https://www.tensorflow.org/)
[![Optuna](https://img.shields.io/badge/Optuna-Hyperparameter%20Tuning-purple)](https://optuna.org/)
[![Plotly](https://img.shields.io/badge/Plotly-Visualization-success)](https://plotly.com/)

## ğŸ“– IntroducciÃ³n

Este proyecto tiene como objetivo **predecir la cantidad de ausencias** de empleados utilizando un modelo de **red neuronal** optimizado con **Optuna**. Se entrenÃ³ la red con datos histÃ³ricos de Recursos Humanos, ajustando los hiperparÃ¡metros para maximizar su rendimiento.

El modelo fue evaluado utilizando mÃ©tricas como **Mean Squared Error (MSE)**, **Mean Absolute Error (MAE)** y **RÂ² Score**, junto con visualizaciones interactivas para facilitar la interpretaciÃ³n de los resultados.

---

## ğŸ¤ Integrantes del Equipo

- **Carolina Salas (ericka.salas@ulead.ac.cr)**
- **Kristhel Porras (kristhel.porras@ulead.ac.cr)**

---

## ğŸ“Œ MetodologÃ­a del Proyecto

### **ğŸ”¹ 1. Preprocesamiento de Datos**
âœ”ï¸ ConversiÃ³n de fechas y tratamiento de valores nulos.  
âœ”ï¸ NormalizaciÃ³n de caracterÃ­sticas numÃ©ricas.  
âœ”ï¸ TransformaciÃ³n de variables categÃ³ricas con One-Hot Encoding.  
âœ”ï¸ DivisiÃ³n en **80% entrenamiento y 20% prueba**.

### **ğŸ”¹ 2. OptimizaciÃ³n de HiperparÃ¡metros con Optuna**
âœ”ï¸ OptimizaciÃ³n de:  
   - **Tasa de aprendizaje (`learning_rate`)**  
   - **TamaÃ±o del batch (`batch_size`)**  
   - **NÃºmero de Ã©pocas (`epochs`)**  
âœ”ï¸ Se probaron mÃºltiples combinaciones para encontrar la mejor configuraciÃ³n.

### **ğŸ”¹ 3. Entrenamiento de la Red Neuronal**
âœ”ï¸ **Arquitectura del Modelo:**
   - Capas ocultas: **256 â†’ 128 â†’ 64 neuronas** con activaciÃ³n **ReLU**.
   - Capa de salida: **1 neurona con activaciÃ³n lineal** (problema de regresiÃ³n).
âœ”ï¸ **FunciÃ³n de pÃ©rdida:** Mean Squared Error (MSE).  
âœ”ï¸ **Optimizador:** Adam.  
âœ”ï¸ **RegularizaciÃ³n:** Uso de **EarlyStopping** para evitar sobreajuste.  

### **ğŸ”¹ 4. EvaluaciÃ³n del Modelo**
âœ”ï¸ CÃ¡lculo de mÃ©tricas **MSE, MAE y RÂ² Score**.  
âœ”ï¸ VisualizaciÃ³n de resultados con **grÃ¡ficos interactivos** en Plotly:
   - **ComparaciÃ³n entre valores reales y predichos** ğŸ“Š
   - **DistribuciÃ³n de errores** ğŸ“‰
   - **Curva de residuos** ğŸ”„
   - **EvoluciÃ³n de la pÃ©rdida y MAE** ğŸ“ˆ

---

## ğŸ“Š ReflexiÃ³n Final del Equipo

### ğŸ”¹ **Uso Inteligente de los Recursos Computacionales**
La cantidad de **trials en Optuna** afecta directamente el **tiempo y los recursos computacionales**. En lugar de probar valores arbitrarios, es recomendable utilizar **Grid Search** o incluso **algoritmos genÃ©ticos** para encontrar configuraciones Ã³ptimas sin desperdiciar capacidad de cÃ³mputo.

### ğŸ”¹ **Visualizaciones Interactivas Facilitan la InterpretaciÃ³n**
Las grÃ¡ficas interactivas permiten **comprender mejor los resultados** y detectar posibles problemas en el modelo. Herramientas como **Plotly** facilitan la identificaciÃ³n de patrones y errores de predicciÃ³n.

### ğŸ”¹ **El Overfitting es un Riesgo Constante**
El uso de **EarlyStopping** fue clave para evitar el sobreajuste. Sin embargo, ajustar la arquitectura del modelo y la cantidad de datos de entrenamiento sigue siendo un desafÃ­o en redes neuronales.

### ğŸ”¹ **Comprender las MÃ©tricas es Fundamental**
Las mÃ©tricas de rendimiento como **MSE, MAE y RÂ² Score** son esenciales para evaluar la calidad del modelo. Entenderlas permite tomar mejores decisiones al ajustar hiperparÃ¡metros y mejorar la generalizaciÃ³n del modelo.

---
